import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing.sequence import pad_sequences
import matplotlib.pyplot as plt

# Load IMDB dataset
num_words = 10000  # Limit to top 10,000 words
maxlen = 200  # Maximum length of each review

(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=num_words)

# Pad sequences to ensure uniform input length
X_train = pad_sequences(X_train, maxlen=maxlen)
X_test = pad_sequences(X_test, maxlen=maxlen)

print(f"Training data shape: {X_train.shape}")
print(f"Test data shape: {X_test.shape}")

# Define the model architecture
model = models.Sequential([
    layers.Embedding(input_dim=num_words, output_dim=128, input_length=maxlen),  # Embedding layer
    layers.GlobalAveragePooling1D(),  # Global average pooling to reduce the sequence length
    layers.Dense(64, activation='relu'),  # Hidden dense layer
    layers.Dense(1, activation='sigmoid')  # Output layer with sigmoid activation (binary classification)
])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Summary of the model
model.summary()

# Train the model
history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))

# Evaluate the model on the test set
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")

# Plot the training and validation accuracy
plt.plot(history.history['accuracy'], label='train accuracy')
plt.plot(history.history['val_accuracy'], label='validation accuracy')
plt.title('Accuracy during training')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Plot the training and validation loss
plt.plot(history.history['loss'], label='train loss')
plt.plot(history.history['val_loss'], label='validation loss')
plt.title('Loss during training')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()


print(f"Number of training samples: {len(X_train)}")
print(f"Number of test samples: {len(X_test)}")
print(f"Number of unique words in the training set: {len(np.unique(np.hstack(X_train)))}")
print(f"Number of unique words in the test set: {len(np.unique(np.hstack(X_test)))}")

# 2. Review Length Distribution
train_lengths = [len(review) for review in X_train]
test_lengths = [len(review) for review in X_test]

# Plot the distribution of review lengths
plt.figure(figsize=(10, 6))
plt.hist(train_lengths, bins=50, alpha=0.7, label="Train Set")
plt.hist(test_lengths, bins=50, alpha=0.7, label="Test Set")
plt.title('Distribution of Review Lengths')
plt.xlabel('Number of Words in Review')
plt.ylabel('Frequency')
plt.legend()
plt.show()

# Plot histogram of the class distribution (positive vs negative reviews)
positive_reviews = np.sum(y_train == 1)
negative_reviews = np.sum(y_train == 0)

plt.figure(figsize=(6, 4))
plt.bar(['Positive', 'Negative'], [positive_reviews, negative_reviews], color=['green', 'red'])
plt.title('Class Distribution (Positive vs Negative Reviews)')
plt.ylabel('Frequency')
plt.show()


# Load the word index
word_index = imdb.get_word_index()

def review_to_sequence(review, word_index, num_words=10000):
    # Converts text to list of word indices
    return [word_index.get(word.lower(), 2) for word in review.split() if word_index.get(word.lower(), 2) < num_words]

# Custom review input (you can change this)
custom_review = "amazing movie"

# Convert to integer sequence and pad it
sequence = review_to_sequence(custom_review, word_index)
padded_sequence = pad_sequences([sequence], maxlen=200)

# Predict sentiment
prediction = model.predict(padded_sequence)[0][0]

# Output result
print("\n--- Custom Review Prediction ---")
print(f"Review: {custom_review}")
print(f"Predicted Sentiment Score: {prediction:.4f}")
print("Sentiment:", "Positive " if prediction >= 0.5 else "Negative ")